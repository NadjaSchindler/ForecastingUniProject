{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These are ideas on what could be presented in out presentation.\n",
    "\n",
    "We do not have to pick all of them!\\\n",
    "But I would appreciate if you could at least spare 10min for each topic researching and getting an idea on what it is about so that we can have some discussions.\\\n",
    "Please add your findings, notes etc inside the different chapters!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General data preprocessing with explanation of why certain steps could be valuable...\n",
    "(resample, excluding of certain values, log transformation,...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://databasecamp.de/daten/data-preprocessing:\n",
    "Data preprocessing:\n",
    "    Vorbereitung von Rohdaten für die Analyse\n",
    "    Rohdaten werden bereinigt, transformiert und integriert\n",
    "    Ziel: Daten von hoher Qualität, konsistent und im richtigen Format für die Analyse zu erhalten\n",
    "    Datenqualität:\n",
    "        Fehler werden identifiziert + korregiert, Duplikate entfernt und fehlende Werte ergänzt\n",
    "    Datenintegration:\n",
    "        Oft: Daten aus mehreren Quellen, sollen in eine Datenbank\n",
    "        Zusammenführung und Umwandlung von Daten aus verschiedenen Quellen (einheitlicher Datensatz)\n",
    "    Datenreduzierung:\n",
    "        Datensatz ist sehr groß + besitzt unnötige oder redundante Informationen -> werden hier entfernt\n",
    "    Normalisierung der Daten:\n",
    "        Daten werden auf einen Standardbereich skaliert -> sorgt für Vergleichbarkeit verschiedener Datensätze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison of different splitting methods:\n",
    "- Index Split\n",
    "- Stratified split\n",
    "- Random Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/data-science-365/random-vs-stratified-splits-5d3d528d445b:\n",
    "Random Split:\n",
    "    Trainings-, Validierungs- und Testdatensätze werden zufällig anhand der Reihenfolge des Index des Datensatzes erstellt\n",
    "    Datensatz sollte vor der Splittung gemischt werden (ansonsten Probleme mit Klassenungleichgewicht)\n",
    "    Scikit-Lern Funktion train_test_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.juliawiki.com/wiki/Data_Splitting:\n",
    "Random Split:\n",
    "    Nützlich, wenn der Datensatz groß und repräsentativ ist\n",
    "\n",
    "Stratified Split:\n",
    "    Oft: Verwendung bei unausgewogenen Datensätzen, bei denen die Verteilung der Zielvariablennicht einheitlich ist\n",
    "    Stellt sicher, dass der Anteil jeder Klasse in verschiedenen Untergruppen konstant bleibt\n",
    "    -> besonders vorteilhaft, um eine unvoreingenommene Bewertung bei Klassifikationsaufgaben aufrechtzuerhalten\n",
    "\n",
    "Time-Based Split:\n",
    "    Eignet sich für zeitliche Daten, bei denen der Datensatz fristgerecht bestellt wird\n",
    "    Teilt die Daten in Trainings- und Testsätze mit einer klaren zeitlichen Grenze auf\n",
    "\n",
    "K-Fold Cross-Validation:\n",
    "    Teilt Daten in K gegenseitig exklusive Falten auf\n",
    "    Jede Falte wird als Validierungssatz verwendet, restlichen K-1-Falten für Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@tubelwj/five-methods-for-data-splitting-in-machine-learning-27baa50908ed:\n",
    "Random Split:\n",
    "    Häufig verwendet\n",
    "\n",
    "Stratified Split:\n",
    "    Sorgt bei unausgeglichenen Datensätzen für Konsistenz in der Klassenverteilung zwischen Trainings-, Validierungs- und Testsätzen\n",
    "\n",
    "Time-Based Split:\n",
    "    Speziell für Zeitreihen entwickelt + besteht aus einer Abfolge von Beobachtungen, die zu verschiedenen Zeitpunkten aufgezeichnet wurden\n",
    "    Herausforderung: Reihenfolge der Datenpunkte ist entscheidend, da Beobachtungen typischerwese von früheren Ereignissen abhängen\n",
    "\n",
    "K-Fold Cross-Validation:\n",
    "    Datensatz wird in \"k\"-Geschwindigkeiten in ebenso skalierte Falten unterteilt, was mehrere Trainings- und Validierungsrunden ermöglicht\n",
    "    Für die Bewertung der Leistungsfähigkeit und Verallgemeinerung von Modellen des maschinellen Lernens\n",
    "    Herausforderung: Modellleistung mit begrenzten Daten effektiv auszuwerten, indem die verfügbaren Proben ausfallen\n",
    "\n",
    "Leave-One-Out Cross-Validation:\n",
    "    Umfassende Cross- Validierungsmethode, besonders für kleine Datensätze geeignet\n",
    "    Jede der N-Proben wird als Testprobe genommen, während restliche N-1-Proben als Trainingsset dienen -> Prozess wird für jede Probe wiederholt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Clustering before Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a method where you cluster different groups of products together before training a model.\n",
    "This could be something like:\n",
    "\n",
    "Cluster v1:\n",
    "Kitchen supplies:\n",
    "- Fork\n",
    "- Knife\n",
    "- Spoon\n",
    "\n",
    "Sport gear:\n",
    "- Bat\n",
    "- Tricot\n",
    "- Running Shoes\n",
    "\n",
    "\n",
    "Cluster v2:\n",
    "Weapons:\n",
    "- Knife\n",
    "- Bat\n",
    "\n",
    "Clothing:\n",
    "- Tricot\n",
    "- Running Shoes\n",
    "\n",
    "Cooking utils:\n",
    "- Fork\n",
    "- Spoon\n",
    "\n",
    "Often these clusters are named after animals such as mule, horse, rabbit, turtle...\\\n",
    "These often reflect different characteristics of a product line like:\n",
    "- Fast and small (rabbit)\n",
    "- Slow and big (mule)\n",
    "- Fast and big (horse)\n",
    "- Slow and small (turtle)\n",
    "\n",
    "Just google these, I did not have the time to read heavily into those yet.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kein Ahnung, ob das folgende das ist, was hier gemeint ist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.neuravest.net/clustering-for-more-effective-model-training-2/:\n",
    "Cluster reduzieren Lärm + verbessern die Datenqualität\n",
    "Bezeihungen werden automatisiert bestimmt und nicht durch meschenbestimmte Etiketten\n",
    "Verkürzt die Trainingszit und erhöht die Vorhersageleistung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/how-to-improve-deep-learning-forecasts-for-time-series-1799e3975d7c:\n",
    "Zwei Arten von Clustering: \n",
    "    Distanzbasiertes Clustering:\n",
    "        Methode zur Minimierung des Abstands zwischen Datenpunkte innerhalb des Clusters\n",
    "    Funktionsbasiertes Clustering:\n",
    "        Verwendet Funktionen, um Datenpunkte in verschiedene Cluster zu gruppieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter for Machine Learning in Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Frequency\n",
    "- Lags\n",
    "- Windows\n",
    "- Model specific stuff..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://link.springer.com/chapter/10.1007/978-3-030-86486-6_30,\n",
    "https://arxiv.org/pdf/2001.10278\n",
    "Frequency: In der Zeitreihenanalyse bezieht sich die Frequenz auf die Anzahl der Beobachtungen pro Zeiteinheit. Zum Beispiel könnte eine tägliche Zeitreihe eine Frequenz von 1 haben, während eine monatliche Zeitreihe eine Frequenz von 1/30 hätte. Die Wahl der Frequenz kann einen erheblichen Einfluss auf die Leistung von Vorhersagemodellen haben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://datascience.stackexchange.com/questions/72480/what-is-lag-in-time-series-forecasting\n",
    "https://www.mdpi.com/2079-9292/10/20/2518\n",
    "https://mikulskibartosz.name/forecasting-time-series-using-lag-features\n",
    "Lags: Ein “Lag” ist ein Zeitverzug in den Daten. Bei der Vorhersage von Zeitreihen werden oft “Lag”-Variablen verwendet, die Werte aus früheren Zeitschritten darstellen. Zum Beispiel könnte man den Umsatz eines Einzelhandelsgeschäfts in Periode t mit dem Umsatz des Vormonats (t-1) als Merkmal vorhersagen. Dies wäre ein Lag von 1. Man könnte sagen, es modelliert eine Art von Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.mlq.ai/time-series-tensorflow-windows-horizons/\n",
    "https://academy.rapidminer.com/courses/using-windowing-on-time-series-data\n",
    "https://machinelearningmastery.com/simple-time-series-forecasting-models/\n",
    "Windows: Bei der Vorhersage von Zeitreihen werden oft “Fenster” von aufeinanderfolgenden Beobachtungen als Eingabe für das Modell verwendet. Die Größe des Fensters (d.h. die Anzahl der Zeitschritte, die es umfasst) kann einen erheblichen Einfluss auf die Leistung des Modells haben. Ein Fenster könnte beispielsweise die Verkaufsdaten der letzten 7 Tage enthalten, um den Verkauf am nächsten Tag vorherzusagen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Optimizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is Optuna?\n",
    "- How does it work?\n",
    "- What is Cross Validation Folding?\n",
    "- How to handle different ranges of parameters?\n",
    "- Show results of different configs..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://datascientest.com/de/optuna:\n",
    "Optuna:\n",
    "    Automatisches Suchwerkzeug zur Optimierung von Hyperparametern -> hilft den optimalen Hyperparameter zu identifizieren\n",
    "    Ermittelt die Kombinationen von Hyperparameter in einem vorher vorgegebenen Raum und optimiert so das ML Modell\n",
    "    Nutzt Stichprobenstrategie (sampling strategy) und Reduktionsstrategie (pruning strategy)\n",
    "    Insgesamt 3 Methoden der Stichprobenstrategie:\n",
    "        Zufallssuche (random search): Zufällige Auswahl der Hyperparameter -> Nützlich, wenn man nicht weiß, nach was gesucht werden soll\n",
    "        Grid Search: Alle Möglichen Kombinationen werden ausprobiert -> Nützlich, wenn man eine bestimmte Idee ausprobieren will, ist jedoch sehr zeitaufwendig, wenn der Suchraum zu groß ist\n",
    "        Bayes´sche Optimierung: Zuerst Zufallssuche, danach werden die Hyperparameter auf der Grundlage der Ergebnisse verfeinert -> oft effektiver als Zufallssuche\n",
    "    Reduktionsstrategie:\n",
    "    Kann unnötige Versuche durch Early Stopping derjenigen Versuche, die am wenigsten aussichtsreich erscheinen, reduzieren\n",
    "\n",
    "    Vorteile:\n",
    "        Benutzerfreundlichkeit\n",
    "        Veschiedene Suchmethoden -> Anpassung an den jeweiligen Anpassungsfall\n",
    "        Kann auf jedes ML Modell angewendet werden\n",
    "        Visualisierung der Ergebnisse -> besseres Verständnis, wie Hyperparameter die Leistung des Modells beeinflussen\n",
    "        Kostenlos + Open-Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://databasecamp.de/ki/cross-validation\n",
    "Cross Validation Folding:\n",
    "    Testet trainierte ML Modelle und bewertet deren Performance unabhängig\n",
    "    Zugrundeliegende Datensatz wird in Trainingsdaten und Testdaten unterteilt -> Genauigkeit des Modells wird ausschließlich auf dem Testdatensatz berechnet -> Beurteilt, wie gut das Modell auf noch nicht gesehene Daten reagiert\n",
    "    CV bietet die Möglichkeit schon im Trainingsprozess die Genauigkeit bzw. die Qualität des Modells bei neuen, ungesehenen Daten abzuschätzen, wie sich die KO nachher in der Realität schlägt\n",
    "    Schritte:\n",
    "        1.Teilen des Trainingsdatensatz in Trainingsdaten und Testdaten\n",
    "        2. Trainieren des Modells mit den Trainingsdaten\n",
    "        3. Validieren der Performance der KI mithilfe der Testdaten\n",
    "        4. Schritte 1-3 wiederholen oder Training beenden\n",
    "\n",
    "Hold-Out Cross Validation:\n",
    "    80% des Datensatzes werden zu Trainings- und 20% zu Testdaten -> Aufteilung kann je nach Datensatz variiert werden\n",
    "    Probleme: Sehr unterschiedliche Verteilung der Elemente im Trainings- und Testdatensatz + sollte nur bei gro0en Datensätzen verwendet werden\n",
    "\n",
    "k-Fold Cross Validation:\n",
    "    Behebt nachteile von Hold-Out Cross Validation -> Trainingsdaten können auch in den Testdaten vorkommen und anders herum\n",
    "    Methode kann auch für kleinere Datensätze genutzt werden\n",
    "    Datensatz wird in k gleichgroße Blöcke unterteilt -> Zufall, welcher Blöch Trainings- / Testdatensatz wird\n",
    "    Im 2ten trainingsschritt wird ein anderer Block als Testdaten definiert und der Prozess wiederholt sich\n",
    "    Anzahl der Blöcke k lässt sich beliebig wäheln -> meist zwischen 5 und 10\n",
    "\n",
    "Vorteile:\n",
    "    robuste Validierungsdaten auch bei kleineren Datensätzen zu erstellen\n",
    "\n",
    "Nachteil:\n",
    "    Abhängig von der Größe des Datensatzes wird eine enorme Rechenleistung benötigt -> sehr zeitintensiv\n",
    "    Komplex\n",
    "    Nicht für alle Datentypen geeignet -> Zeitreihen gehen nicht, weil wichtige Infos verloren gehen können\n",
    "    Daten müssen aus einer normalverteilten Distribution stammen\n",
    "    Information Leakage, wenn Daten stark miteinander korreliert sind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing...\n",
    "- different splitting methods (what happens if you exclude a whole product line from training?)\n",
    "- different hyperparameter\n",
    "- different model (XGBoost, LightGBM, 1-2 from the class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecasting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
